# -*- coding: utf-8 -*-
"""ImageClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-Xprg11V6hiUyNHOizqGCrs1y1bJO-ay
"""

from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/My\ Drive/Colab\ Notebooks/caltech_dataset

from google.colab.patches import cv2_imshow
import cv2
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC            
from skimage import exposure
from skimage import feature
from imutils import paths
import imutils
from sklearn.decomposition import PCA

# Function to compute histogram from LBP features
	def compute_lbp(image, eps=1e-7,numPoints=24,radius=8):
		# compute the Local Binary Pattern representation
		# of the image, and then use the LBP representation
		# to build the histogram of patterns
		lbp = feature.local_binary_pattern(image, numPoints,
			radius, method="uniform")
		(hist, _) = np.histogram(lbp.ravel(),
			bins=np.arange(0, numPoints + 3),
			range=(0, numPoints + 2))
		# normalize the histogram
		hist = hist.astype("float")
		hist /= (hist.sum() + eps)
		# return the histogram of Local Binary Patterns
		return hist

"""# Feature extraction   from the training data with the corresponding labels"""

print("[INFO] Extracting different features:  Raw Pixel values from image/Color Histogram/HOG/LBP")
x_train_hog=[]
x_train_lbp=[]
x_train_hsv=[]
x_train_image=[]
y_train=[]

for imagePath in paths.list_images('train_set'):
 
  # Retrieve the name of the class from each image path 
  image_label=imagePath.split('/',3)[1]
  print (image_label)
  y_train.append(image_label)

  #Display the image
  image=cv2.imread(imagePath)
  #Make images with same size
  image=cv2.resize(image,(200,100))
  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  cv2_imshow(gray_image)

  #Discripteur image
  v=gray_image.flatten()
  x_train_image.append(v)

  #Test if they have same size 
  print (len(x_train_image))
  print (len(y_train))

  #HOG
  (H, hogImage) = feature.hog(gray_image, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2),transform_sqrt=True, block_norm="L1",visualize=True)
  hogImage = exposure.rescale_intensity(hogImage, out_range=(0, 255))
  hogImage = hogImage.astype("uint8")
  print ("hog images")


  #TODO: Display HOG image
  cv2_imshow(hogImage)
  x_train_hog.append(H)
    
  #LBP
  v_lbp=compute_lbp(gray_image)
  x_train_lbp.append(v_lbp)

  #HSV
  image_hsv=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)
  hist1=cv2.calcHist([image_hsv], [0, 1],None, [180, 256], [0, 180, 0, 256])
  hist1_flat=hist1.flatten()
  x_train_hsv.append(hist1_flat)

x_train_image

y_train

x_train_lbp

x_train_hsv

#TODO: Print the size of each feature vector 
#...

"""# Feature extraction from the testing data with the corresponding labels"""

test_data_image=[]
x_test_hog=[]
x_test_lbp=[]
x_test_hsv=[]
y_test_labels=[]
# compute the different features on the testing set and stock the  corresponding test labels
for imagePath in paths.list_images('test_set'):
 
  # Retrieve the name of the class from each image path 
  image_label_test=imagePath.split('/',3)[1]
  print (image_label_test)
  y_test_labels.append(image_label_test)

  #Display the image
  image=cv2.imread(imagePath)
  #Make images with same size
  image=cv2.resize(image,(200,100))
  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  cv2_imshow(gray_image)

  #Discripteur image
  v=gray_image.flatten()
  test_data_image.append(v)


  #Discripteur HOG
  (H, hogImage) = feature.hog(gray_image, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2),transform_sqrt=True, block_norm="L1",visualize=True)
  hogImage = exposure.rescale_intensity(hogImage, out_range=(0, 255))
  hogImage = hogImage.astype("uint8")

  #Append HOG Image To Data test
  
  x_test_hog.append(H)

  #Discripteur LBP
  v_lbp=compute_lbp(gray_image)
  x_test_lbp.append(v_lbp)
    #HSV

  image_hsv_test=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)
  hist_test=cv2.calcHist([image_hsv_test], [0, 1],None, [180, 256], [0, 180, 0, 256])
  hist_test_flat=hist_test.flatten()
  x_test_hsv.append(hist_test_flat)

test_data_image

"""# SVM and KNN models"""

model1 = KNeighborsClassifier(n_neighbors=1)
model2 = SVC(kernel='linear')

"""# Train SVM and KNN models and predict the results, evaluate them as well!"""

# Train and predict based on model 1, evalute your results as well!
model1.fit(x_train_image, y_train)
predicted_classes1 = model1.predict(test_data_image)
predicted_classes1

print ("Accuracy With KNN: ")
accuracy=sum(y_test_labels==predicted_classes1)/(len(y_test_labels))
accuracy
#TODO: evaluate the obtained results by comparing the predicted classes to the ground truth
#....

#WITH HOG
model1.fit(x_train_hog, y_train)
predicted_classes1 = model1.predict(x_test_hog)
predicted_classes1

print ("Accuracy With KNN For HOG : ")
accuracy=sum(y_test_labels==predicted_classes1)/(len(y_test_labels))
accuracy

#WITH HOG
model2.fit(x_train_hog, y_train)
predicted_classes1 = model2.predict(x_test_hog)
predicted_classes1

print ("Accuracy With KNN For HOG : ")
accuracy=sum(y_test_labels==predicted_classes1)/(len(y_test_labels))
accuracy

#WITH LBP
model1.fit(x_train_lbp, y_train)
predicted_classes1 = model1.predict(x_test_lbp)
predicted_classes1

print ("Accuracy With KNN For LBP : ")
accuracy=sum(y_test_labels==predicted_classes1)/(len(y_test_labels))
accuracy

#WITH LBP
model2.fit(x_train_lbp, y_train)
predicted_classes1 = model2.predict(x_test_lbp)
predicted_classes1

print ("Accuracy With SVM For LBP : ")
accuracy=sum(y_test_labels==predicted_classes1)/(len(y_test_labels))
accuracy

# Train and predict based on model 2, evalute your results as well!model1.fit(x_train_image, y_train)
model2.fit(x_train_image, y_train)
predicted_classes2 = model2.predict(test_data_image)
predicted_classes2

print ("Accuracy  with  SVM: ")
accuracy2=sum(y_test_labels==predicted_classes1)/(len(y_test_labels))
accuracy2

#WITH HSV
model1.fit(x_train_hsv, y_train)
predicted_classes1 = model1.predict(x_test_hsv)
predicted_classes1

print ("Accuracy With KNN For HSV : ")
accuracy=sum(y_test_labels==predicted_classes1)/(len(y_test_labels))
accuracy

# Train and predict based on model 2, evalute your results as well!model1.fit(x_train_image, y_train)
model2.fit(x_train_hsv, y_train)
predicted_classes2 = model2.predict(x_test_hsv)
predicted_classes2

print ("Accuracy  with  SVM FOR HSV : ")
accuracy2=sum(y_test_labels==predicted_classes1)/(len(y_test_labels))
accuracy2

"""# Feature Selection by PCA"""

#TODO: Apply PCA  on LBP features, retrain the two models after selection  and predict the results, dont forget to evaluate and to compare regarding the original LBP features

from sklearn.decomposition import PCA
pca = PCA()
#
# Determine transformed features
#
X_train_pca = pca.fit_transform(x_train_lbp)
X_test_pca = pca.transform(x_test_lbp)

print(X_train_pca)
print(X_test_pca)

model2.fit(X_train_pca, y_train)
predicted_classes1 = model2.predict(X_test_pca)
predicted_classes1

print ("Accuracy  with  PCA: ")
accuracy2=sum(y_test_labels==predicted_classes1)/(len(y_test_labels))
accuracy2